\chapter{Additional Algorithms} \label{chap:additional-algorithms}
The following algorithms are still not yet mature enough to be considered core-functionality, and/or are available with the {\OpenCL} backend only.

\section{Additional Iterative Solvers}
The following iterative solvers are only available on selected computing backends.

\subsection{Mixed-Precision Conjugate Gradients}
A two-stage mixed-precision CG algorithm is available as follows:
\begin{lstlisting}
viennacl::linalg::mixed_precision_cg_tag   mixed_prec_cg_config;
vcl_result = viennacl::linalg::solve(vcl_matrix,
                                     vcl_rhs,
                                     mixed_prec_cg_config);
\end{lstlisting}
As usual, the first parameter to the constructor of \lstinline|mixed_precision_cg_tag| is the relative tolerance for the residual, while the second parameter denotes the maximum number of solver iterations.
The third parameter denotes the relative tolerance for the inner low-precision CG iterations and defaults to $0.01$.

\TIP{Have a look at \lstinline|examples/banchmarks/solver.cpp| for an example.}

\NOTE{A mixed-precision solver makes sense only if the matrix and right-hand-side vector are supplied in \lstinline|double| precision.}

\NOTE{The mixed-precision solver is currently available with the {\OpenCL} compute backend only.}

\section{Additional Preconditioners}
In addition to the preconditioners discussed in Sec.~\ref{sec:preconditioner}, two more preconditioners are available with the {\OpenCL} backend and are described in the following.

\subsection{Algebraic Multigrid}
\NOTE{Algebraic Multigrid preconditioners are only available with the {\OpenCL} backend and are experimental in {\ViennaCLversion}. Interface changes as well as considerable performance improvements may
be included in future releases!}

\NOTE{Algebraic Multigrid preconditioners depend on {\ublas}.}

Algebraic multigrid mimics the behavior of geometric multigrid on the algebraic level and is thus suited for black-box purposes, where only the system matrix
and the right hand side vector are available \cite{trottenberg:multigrid}. Many different flavors of the individual multigrid ingredients exists
\cite{yang:parallel-amg}, of which the most common ones are implemented in {\ViennaCL}.

The two main ingredients of algebraic multigrid are a coarsening algorithm and an interpolation algorithm. The available coarsening methods are listed in
Tab.~\ref{tab:amg-coarsening}.
\begin{table}[tbp]
\begin{center}
\begin{tabular}{l|l}
Description & {\ViennaCL} option constant \\
\hline
Classical Ruge-St\"uben (RS) & \lstinline|VIENNACL_AMG_COARSE_RS| \\
One-Pass & \lstinline|VIENNACL_AMG_COARSE_ONEPASS| \\
RS0 & \lstinline|VIENNACL_AMG_COARSE_RS0| \\
RS3 & \lstinline|VIENNACL_AMG_COARSE_RS3| \\
Aggregation & \lstinline|VIENNACL_AMG_COARSE_AG| \\
Smoothed aggregation & \lstinline|VIENNACL_AMG_COARSE_SA| \\
\end{tabular}
\caption{AMG coarsening methods available in {\ViennaCL}. Per default, classical RS coarsening is used.\label{tab:amg-coarsening}}
\end{center}
\end{table}
The available interpolation methods are given in Tab.~\ref{tab:amg-interpolation}.
\begin{table}[tbp]
\begin{center}
\begin{tabular}{l|l}
Description & {\ViennaCL} option constant \\
\hline
Direct & \lstinline|VIENNACL_AMG_INTERPOL_DIRECT| \\
Classic & \lstinline|VIENNACL_AMG_INTERPOL_ONEPASS| \\
RS0 coarsening & \lstinline|VIENNACL_AMG_INTERPOL_RS0| \\
RS3 coarsening & \lstinline|VIENNACL_AMG_INTERPOL_RS3| \\
\end{tabular}
\caption{AMG interpolation methods available in {\ViennaCL}. Per default, direct interpolation is used.\label{tab:amg-interpolation}}
\end{center}
\end{table}
In addition, the following parameters can be controlled in the \lstinline|amg_tag| and can be passed to the constructor:
\begin{itemize}
 \item Strength of dependence threshold (default: $0.25$)
 \item Interpolation weight (default: $1$)
 \item Jacobi smoother weight (default: $1$)
 \item Number of pre-smoothing steps (default: $1$)
 \item Number of post-smoothing steps (default: $1$)
 \item Number of coarse levels
\end{itemize}

\TIP{Note that the efficiency of the various AMG flavors are typically highly problem-specific. Therefore, failure of one method for a particular problem does
NOT imply that other coarsening or interpolation strategies will fail as well.}

\subsection{Sparse Approximate Inverses}

\NOTE{Sparse Approximate Inverse preconditioners are only available with the {\OpenCL} backend and are experimental in {\ViennaCLversion}. Interface changes as well as considerable performance improvements may
be included in future releases!}

\NOTE{Sparse Approximate Inverse preconditioners depend on {\ublas}.}

An alternative construction of a preconditioner for a sparse system matrix $A$ is to compute a matrix $M$ with a prescribed sparsity pattern such that
\begin{align}
 \Vert AM - I \Vert_F \rightarrow \min \ ,
\end{align}
where $\Vert \cdot \Vert_F$ denotes the Frobenius norm.
This is the basic idea of sparse approximate inverse (SPAI) preconditioner. It becomes increasingly attractive because of their inherent high degree of
parallelism, since the minimization problem can be solved independently for each column of $M$. {\ViennaCL} provides two preconditioners of
this family: The first is the classical SPAI algorithm as described by Grote and Huckle \cite{grote:spai}, the second is the factored SPAI (FSPAI) for symmetric
matrices as proposed by Huckle \cite{huckle:fspai}.

SPAI can be employed for a CPU matrix \lstinline|M| of type \lstinline|MatrixType| as follows:
\begin{lstlisting}
// setup SPAI preconditioner, purely CPU-based
viennacl::linalg::spai_precond<MatrixType>
  spai_cpu(M, viennacl::linalg::spai_tag(1e-3, 3, 5e-2));

//solve (e.g. using stab. Bi-conjugate gradient solver)
vcl_result = viennacl::linalg::solve(M,
                                     rhs,
                                     viennacl::linalg::bicgstab_tag(),
                                     spai_cpu);
\end{lstlisting}
The first parameter denotes the residual norm threshold for the full matrix, the second parameter the maximum number of pattern updates, and the third
parameter is the threshold for the residual of each minimization problem.

For GPU-matrices, only parts of the setup phase are computed on the CPU, because compute-intensive tasks can be carried out on the GPU:
\begin{lstlisting}
// setup SPAI preconditioner, GPU-assisted
viennacl::linalg::spai_precond<GPUMatrixType>
  spai_gpu(vcl_matrix, viennacl::linalg::spai_tag(1e-3, 3, 5e-2));

//solve (e.g. using conjugate gradient solver)
vcl_result = viennacl::linalg::solve(vcl_matrix,
                                     vcl_rhs,
                                     viennacl::linalg::bicgstab_tag(),
                                     spai_gpu);
\end{lstlisting}
The \lstinline|GPUMatrixType| is typically a \lstinline|viennacl::compressed_matrix| type.

For symmetric matrices, FSPAI can be used with the conjugate gradient solver:
\begin{lstlisting}
viennacl::linalg::fspai_precond<MatrixType> fspai_cpu(M, viennacl::linalg::fspai_tag());

//solve (e.g. using stab. Bi-conjugate gradient solver)
vcl_result = viennacl::linalg::solve(M,
                                     rhs,
                                     viennacl::linalg::cg_tag(),
                                     fspai_cpu);
\end{lstlisting}
Our experience is that FSPAI is typically more efficient than SPAI when applied to the same matrix, both in computational effort and in terms of convergence
acceleration of the iterative solvers.

\NOTE{At present, there is no GPU-accelerated FSPAI included in {\ViennaCL}.}

Note that FSPAI depends on the ordering of the unknowns, thus bandwidth reduction algorithms may be employed first, cf.~Sec.~\ref{sec:bandwidth-reduction}.


\section{Fast Fourier Transform}

Fast Furier Transformation is available with {\OpenCL},{\CUDA},{\OpenMP} backends.

Since there is no standardized complex type in {\OpenCL} at the time of the release of {\ViennaCLversion}, vectors need to be set up with real- and imaginary
part before computing a fast Fourier transform (FFT). In order to store complex numbers $z_0$, $z_1$, etc.~in a \lstinline|viennacl::vector|, say \lstinline|v|,
the real and imaginary parts are mapped to even and odd entries of \lstinline|v| respectively: \lstinline|v[0] = Real(z_0)|, \lstinline|v[1] = Imag(z_0)|,
\lstinline|v[2] = Real(z_1)|, \lstinline|v[3] = Imag(z_1)|, etc.

The FFT of \lstinline|v| can then be computed either by writing to a second vector \lstinline|output| or by directly writing the result to \lstinline|v|
\begin{lstlisting}
 viennacl::fft(v, output);
 viennacl::inplace_fft(v);
\end{lstlisting}
Conversely, the inverse FFT is computed as
\begin{lstlisting}
 viennacl::ifft(v, output);
 viennacl::inplace_ifft(v);
\end{lstlisting}

Second possibility to compute FFT is with Bluestein algorithm. Currently,  Works only for sizes of input data which is less than $2^{16}$. Uses a lot of additional memory, but should be fast for any size of data. Bluestein algorithm uses at least three-times more additional memory than another algorithms. Serial implementation has something about $o(n * \lg n)$ complexity.
Compute FFT with Bluestein algorithm from complex vector \lstinline|v| and store result in vector \lstinline|output| user can do with function
\begin{lstlisting}
 viennacl::linalg::bluestein(v, output,batch_size);
\end{lstlisting}

\NOTE{In {\ViennaCLversion} the FFT with complexity $N \log N$ is computed for vectors with a size of a power of two only. For other vector sizes, a standard
discrete Fourier transform with complexity $N^2$ is employed. This is subject to change in future versions.}

Some of the FFT functions are also suitable for matrices and can be computed in 2D. FFT of \lstinline|viennacl::matrix|, say  \lstinline|mat| , where also the even entries are real parts and odd entries are imaginary parts of complex numbers. In order to store complex numbers $z_0$, $z_1$, etc.~in \lstinline|mat|: \lstinline|mat(0,0) = Real(z_0)|, \lstinline|mat(0,1) = Imag(z_0)|,\lstinline|mat(0,2) = Real(z_0)|, \lstinline|mat(0,3) = Imag(z_0)| etc.

Than user can compute FFT  either by writing to a second matrix \lstinline|output| or by directly writing the result to \lstinline|mat| 
\begin{lstlisting}
 viennacl::fft(mat, output);
 viennacl::inplace_fft(v);
\end{lstlisting}

\NOTE{In {\ViennaCLversion} the FFT with complexity $N \log N$ is computed for matrices with a number of rows and columns a power of two only. For other matrix sizes, a standard
discrete Fourier transform with complexity $N^2$ is employed. This is subject to change in future versions.}

ViennaCL covers also the possibility to transpose matrix \lstinline|mat| which can be either used to store result in  matrix \lstinline|output| or by directly writing the result to matrix  \lstinline|output|
\begin{lstlisting}
viennacl::linalg::transpose(mat,output);
viennacl::linalg::transpose(mat);
\end{lstlisting}

\NOTE{In {\ViennaCLversion} the transpose function works just for square matrix}

There are two additional functions to calculate Convolution. It expresses the amount of overlap of one function represented by vector \lstinline|v| as it is shifted over another function represented by vector \lstinline|u|. Convolution is defined by integral 
$$(v*u)(t) = \int_{-\infty}^\infty f(x)g(t-x) dx$$ Define $F$ as Fast Fourier Transform operator, so we can define convolution of two infinite sequences  \lstinline|v| and  \lstinline|u| as 
$$F\{v*u\} = F\{u\}F\{v\} \rightarrow v*u = F^{-1}\{F\{v\}F\{u\}\}$$
In other words, convolution in time domain is equals  multiplication in the frequency domain. To compute this function from two complex vectors \lstinline|v| and \lstinline|u| where the result will be stored in \lstinline|output| can be computed with additional memory allocating of three vectors with size \lstinline|v.size()| as  
\begin{lstlisting}
 viennacl::linalg::convolve(v,u,output);
\end{lstlisting}
or without additional memory allocations as
\begin{lstlisting}
 viennacl::linalg::convolve_i(v,u,output);
\end{lstlisting}

\NOTE{This function can make changes in input vectors!}

Multiplication of two complex vectors \lstinline|u|, \lstinline|v| where the result will be stored in \lstinline|output| vector is covered in function
\begin{lstlisting}
 viennacl::linalg::multiply_complex(u,v,output);
\end{lstlisting}

For computing complex vector \lstinline|v| from real vector \lstinline|u| with length \lstinline|size = v.size() / 2| can be used function
\begin{lstlisting}
 viennacl::linalg::real_to_complex(u,v,size);
\end{lstlisting}
or in opposite direction, computing real vector \lstinline|v| from complex vector \lstinline|u| with length \lstinline|size = v.size() / 2| 
\begin{lstlisting}
 viennacl::linalg::complex_to_real(u,v,size);
\end{lstlisting}

Reverse vector \lstinline|v| to oposite order and save it in vector \lstinline|v| user can use
function 
\begin{lstlisting}
 viennacl::linalg::reverse(v);
\end{lstlisting}

\section{Bandwidth Reduction} \label{sec:bandwidth-reduction}
\NOTE{Bandwidth reduction algorithms are experimental in {\ViennaCLversion}. Interface changes as well as considerable performance improvements may
be included in future releases!}

The bandwidth of a sparse matrix is defined as the maximum difference of the indices of nonzero entries in a row, taken over all rows. A low bandwidth
typically allows for the use of efficient banded matrix solvers instead of iterative solvers. Moreover, better cache utilization as well as lower fill-in in
LU-factorization based algorithms can be expected.

For a given sparse matrix with large bandwidth, {\ViennaCL} provides routines for renumbering the unknowns such that the reordered system matrix shows much
smaller bandwidth. Typical applications stem from the discretization of partial differential equations by means of the finite element or the finite difference
method. The algorithms employed are as follows:
\begin{itemize}
 \item Classical Cuthill-McKee algorithm \cite{cuthill:reducing-bandwidth}
 \item Iterated Cuthill-McKee algorithm with different seeds \cite{cuthill:reducing-bandwidth}
 \item Gibbs-Poole-Stockmeyer algorithm, cf.~\cite{lewis:gps-algorithm}
\end{itemize}
The iterated Cuthill-McKee algorithm applies the classical Cuthill-McKee algorithm to different starting nodes with small, but not necessarily minimal degree as root node into account.
While this iterated application is more expensive in times of execution times, it may lead to better results than the classical Cuthill-McKee algorithm.
A parameter $a \in [0,1]$ controls the number of nodes considered: All nodes with degree $d$ fulfilling
\begin{align*}
 d_{\min} \leq d \leq d_{\min} + a(d_{\max} - d_{\min})
\end{align*}
are considered, where $d_{\min}$ and $d_{\max}$ are the miminum and maximum nodal degrees in the graph.
A second parameter \lstinline|gmax| specifies the number of additional root nodes considered.

The algorithms are called for a \lstinline|matrix| of a type compatible with \lstinline|std::vector< std::map<int, double> >| by
\begin{lstlisting}
 r = viennacl::reorder(matrix, viennacl::cuthill_mckee_tag());
 r = viennacl::reorder(matrix,
                       viennacl::advanced_cuthill_mckee_tag(a, gmax));
 r = viennacl::reorder(matrix, viennacl::gibbs_poole_stockmeyer_tag());
\end{lstlisting}
and return the permutation array. In {\ViennaCLversion}, the user then needs to manually reorder the sparse matrix based on the permutation array. Example code
can be found in \lstinline|examples/tutorial/bandwidth-reduction.cpp|.


\section{Nonnegative Matrix Factorization}
\NOTE{Nonnegative Matrix Factorization is experimental in {\ViennaCLversion} and available with the {\OpenCL} backend only.
      Interface changes as well as considerable performance improvements may be included in future releases!}

In various fields such as text mining, a matrix $V$ needs to be factored into factors $W$ and $H$ such that the function
\begin{align*}
 f(W, H) = \Vert V - WH \Vert_{\mathrm{F}}^2
\end{align*}
is minimized. The algorithm proposed by Lee and Seoung \cite{lee:nmf} is available in ViennaCL in the header file \texttt{viennacl/linalg/nmf.hpp} as
\begin{lstlisting}
 viennacl::matrix<ScalarType> V(size1, size2);
 viennacl::matrix<ScalarType> W(size1, k);
 viennacl::matrix<ScalarType> H(k, size2);

 viennacl::linalg::nmf_config conf;
 viennacl::linalg::nmf(v_ref, w_nmf, h_nmf, conf);
\end{lstlisting}
For an overview of the parameters (tolerances) of the configuration object \lstinline|conf|, please refer to the Doxygen documentation in \texttt{doc/doxygen/}.
